{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b67516b",
   "metadata": {},
   "source": [
    "# TP3 : Chaînes de Markov à espace d'états fini"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10d5293",
   "metadata": {},
   "source": [
    "On commence par importer les bibliothèques usuelles :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0987c556",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14de24a0",
   "metadata": {},
   "source": [
    "## 1 - Introduction aux matrices dans Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d96f8b5",
   "metadata": {},
   "source": [
    "Pour représenter les matrices (et vecteurs) dans Python, on utilise le type `np.array`, similaire aux listes. La syntaxe est cohérente avec ce que vous avez appris en algèbre linéaire, à ceci près que les indices commencent à $0$ pour les lignes et les colonnes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b42729f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 9]]\n",
      "2\n",
      "[3 6 9]\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[1,2,3],[4,5,6],[7,8,9]])\n",
    "print(A) # La matrice A\n",
    "print(A[0,1]) # Le coefficient de la 1ere ligne, 2eme colonne.\n",
    "print(A[:,2]) # La 3eme colonne"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4e38c4",
   "metadata": {},
   "source": [
    "Dans la dernière ligne, on a utilisé ce qu'on appelle un slice: pour une liste `L` donnée, `L[i:j]` renvoie la liste des élèments `L[k]` pour `i`$\\leq$ `k` $<$`j`.On peut le voir comme un raccourci de\n",
    "`[L[k] for k in range(i,j)]`. \n",
    "\n",
    "En omettant `i` devant les deux points, on demande tous les éléments de la liste jusqu'à `j`. En omettant `j` après les deux points, on demande tous les éléments de la liste après `i`. Finalement, en omettant les deux, on demande tous les éléments de la liste.\n",
    "\n",
    "On peut l'utiliser dans les `np.array` pour sélectionner des parties de la matrice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a285e3",
   "metadata": {},
   "source": [
    "1) Écrire un code qui affiche la deuxième ligne de la matrice $A$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251d6073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f75f2a",
   "metadata": {},
   "source": [
    "2) Afficher la multiplication de $\\pi$ et $A$, avec $\\pi=\\left(2,3,4\\right)$ vu comme un vecteur ligne. La multiplication se fait par la commande `np.dot`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1d3eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b44d1d",
   "metadata": {},
   "source": [
    "On trouvera dans `np.linalg` une large palette de fonctions classiques d'algèbre linéaire: déterminant, norme, inverse, valeurs et vecteurs propres."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21bae8b7",
   "metadata": {},
   "source": [
    "## 2 - Chaînes de Markov"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a58dc3",
   "metadata": {},
   "source": [
    "### 1er exemple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61021574",
   "metadata": {},
   "source": [
    "On reprend l'exercice du TD1 : "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b9eca4",
   "metadata": {},
   "source": [
    "Un fumeur, après avoir lu une série de statistiques sur les risques de cancer et de problèmes cardio-vasculaires liés au tabac, décide d’arrêter de fumer ; toujours d’après des statistiques, on estime les probabilités suivantes : si cette personne n’a pas fumé un jour $n$, alors la probabilité pour qu’elle ne fume pas le jour suivant $n+1$ est 0.3; mais si elle a fumé un jour $n$, alors la probabilité pour qu’elle ne fume pas le jour suivant $n+1$ est 0.9. Comment modéliser le comportement de cette personne ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73b46e5",
   "metadata": {},
   "source": [
    "On introduit pour cela une suite de variables aléatoires $(X_n)_{n\\geq0}$ à valeurs dans $\\{0,1\\}$, avec $n$ qui représente le temps, c'est-à-dire le jour $n$, et $X_n=1$ si la personne a fumé le jour $n$ et $X_n=0$ sinon."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76cb33ad",
   "metadata": {},
   "source": [
    "On a donc les probabilités conditionnelles suivantes :\n",
    "$$\n",
    "\\mathbb P(X_{n+1}=0 | X_n=0)=0.3 \\quad \\text{et} \\quad \\mathbb P(X_{n+1}=1 | X_n=0)=0.7\n",
    "$$\n",
    "et\n",
    "$$\n",
    "\\mathbb P(X_{n+1}=0 | X_n=1)=0.9 \\quad \\text{et} \\quad \\mathbb P(X_{n+1}=1 | X_n=1)=0.1\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd72934a",
   "metadata": {},
   "source": [
    "On résume ces probabilités dans la matrice de transition suivante :\n",
    "$$\n",
    "Q=\\begin{pmatrix} 0.3 & 0.7 \\\\ 0.9 & 0.1  \\end{pmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16155305",
   "metadata": {},
   "source": [
    "1) Définir la matrice $Q$ à l'aide de `np.array`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b332717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd59859",
   "metadata": {},
   "source": [
    "La suite $(X_n)_{n\\geq0}$ est un exemple de chaîne de Markov à 2 états (0 ou 1), de matrice de transition $Q$, c'est-à-dire :\n",
    "$$\n",
    "\\mathbb P(X_{n+1}=y | X_n=x)=Q(x,y),\n",
    "$$\n",
    "pour tout $x,y \\in \\{0,1\\}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06582ca5",
   "metadata": {},
   "source": [
    "La première ligne de $Q$ donne donc la loi conditionnelle de $X_{n+1}$ sachant $X_n=0$, et la deuxième ligne de $Q$ la loi conditionnelle de $X_{n+1}$ sachant $X_n=1$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97d0c51",
   "metadata": {},
   "source": [
    "On a en fait mieux, la propriété de Markov énonce que le futur ne dépend pas du passé, mais uniquement du présent, c'est-à-dire :\n",
    "$$\n",
    "\\mathbb P(X_{n+1}=x_{n+1} | X_{n}=x_{n}, \\ldots, X_{0}=x_{0}) = \\mathbb P(X_{n+1}=x_{n+1} | X_{n}=x_{n}), \n",
    "$$\n",
    "pour tous $x_0,\\ldots,x_{n+1} \\in \\{0,1\\}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca2b48b",
   "metadata": {},
   "source": [
    "On va simuler le comportement de cette chaîne. Pour cela, on a besoin au temps $n+1$ de tirer au hasard un 0 ou un 1 selon qu'on est au temps $n$ dans l'état 0 ou l'état 1. On va pour cela utiliser la commande `random.choice` qui permet de tirer au hasard un entier selon une loi prescrite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eaf7e403",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.choice(a=2,p=[.3,.7]) # tire un échantillon de taille 1 dans a=np.arange(2)=[0,1] selon la loi p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e03890",
   "metadata": {},
   "source": [
    "La commande ci-dessus a donc retourné la valeur de $X_{n+1}$ sachant que $X_n=0$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79fea19",
   "metadata": {},
   "source": [
    "2) Écrire une commande `markov(x)` qui simule $X_{n+1}$ selon qu'on est en $x=$ 0 ou 1 au temps $n$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab687a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Solution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d131dc45",
   "metadata": {},
   "source": [
    "3) Écrire une fonction `traj_markov(x,n)` qui simule une trajectoire de $n$ étapes de la chaine, en commençant dans l'état initial $X_0 = x$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d639c3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00675dcb",
   "metadata": {},
   "source": [
    "On peut alors étudier le comportement en temps de la chaîne et répondre par exemple aux questions : combien de temps le fumer passe t-il à fumer ? Le fumeur va-t-il finir par s'arrêter de fumer ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd946bf1",
   "metadata": {},
   "source": [
    "4) Commençons par regarder combien de temps la chaîne passe dans l'état 0.\n",
    "1. Définir z0 une trajectoire de la chaîne de Markov, pour $n=1000$ pas, commençant en 0.\n",
    "2. Définir et faire un graphe de y0 la suite des moyennes empiriques du nombre de visites en 0 de la chaîne (on pourra s'inspirer de l'exercice 3 du TP 2).\n",
    "3. Faire de même pour y1, les fréquences d'occupation de 0 pour une trajectoire commençant en 1.\n",
    "4. Que remarquez-vous ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665b9283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e66df7",
   "metadata": {},
   "source": [
    "En général, la quantité\n",
    "$$\n",
    "\\frac{1}{n} \\sum_{k=0}^{n-1} \\mathbb 1_{\\{X_n=k\\}}\n",
    "$$\n",
    "s'interprète comme le taux d'occupation de l'état $k$ jusqu'au temps $n$.\n",
    "\n",
    "On veut maintenant savoir avec quelle probabilité le fumeur va s'arrêter de fumer.  On cherche donc à déterminer la loi de $X_n$ quand $n$ est grand. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890f7855",
   "metadata": {},
   "source": [
    "On peut pour cela, déterminons la mesure empirique d'un échantillon de $X_n$.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da425b91",
   "metadata": {},
   "source": [
    "5) Écrire une fonction `echantillon_markov(n,m)` qui renvoie un échantillon de taille $m$ de la variable $X_n$ (d'état initial $X_0=0$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1c99bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Solution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0cb56f",
   "metadata": {},
   "source": [
    "6) Afficher un diagramme en barre de la mesure empirique de la loi de $X_n$ (on pourra s'inspirer de l'exercice 6 du TP1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ecfe256",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Solution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ded751",
   "metadata": {},
   "source": [
    "Tester pour différentes valeurs de $n$ et $m$. Interpréter la figure ci-dessus et comparer avec le résultat numérique obtenu au TD1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9d37c9",
   "metadata": {},
   "source": [
    "On appelle probabilité invariante une probabilité $\\pi$ vu comme un vecteur ligne dont les coefficients somment à 1, vérifiant :\n",
    "$$\n",
    "\\pi = \\pi Q\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f7fa33",
   "metadata": {},
   "source": [
    "La loi de $X_n$ selon l'état initial est donné par la puissance $n$-ième $Q^n$ de la matrice $Q$, c'est-à-dire que\n",
    "$$\n",
    "\\mathbb P(X_n = y | X_0=x) = Q^n(x,y).\n",
    "$$\n",
    "On a donc que si $X_0$ est distribué selon $\\pi$, alors $X_n$ est de loi $\\pi$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ffd98d4",
   "metadata": {},
   "source": [
    "7) Vérifiez que la probabilité $\\pi=(\\frac{9}{16} \\frac{7}{16})$ est une probabilité invariante pour la matrice $Q=\\begin{pmatrix} 0.3 & 0.7 \\\\ 0.9 & 0.1 \\end{pmatrix}$ de l'introduction. Le produit de matrices se fait à l'aide la commande `np.dot`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0324a790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e52f7da",
   "metadata": {},
   "source": [
    "Il faut faire attention quand on compare des valeurs numériques, par exemple :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94827d0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(2)*np.sqrt(2) == 2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb68dc5",
   "metadata": {},
   "source": [
    "On peut utiliser la commande `isclose` pour comparer des valeurs numériques à la précision de la machine utilisée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7e66c45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isclose(np.sqrt(2)*np.sqrt(2), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9a24f9",
   "metadata": {},
   "source": [
    "### 2ème exemple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ddda9ba",
   "metadata": {},
   "source": [
    "On considère une chaîne à 3 états, de probabilités de transition données par la matrice $P$ :\n",
    "$$\n",
    "P=\\begin{pmatrix} 0 & \\frac12 & \\frac12 \\\\ \\frac14 & \\frac12 & \\frac14 \\\\ \\frac14 & \\frac14 & \\frac12  \\end{pmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd74e2ab",
   "metadata": {},
   "source": [
    "0) Definir la matrice $P$ à l'aide la commande `np.array`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572ec37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22facbaf",
   "metadata": {},
   "source": [
    "1) Ecrire une commande qui prend en entrée $x,R,n$ et qui renvoie la trajectoire jusqu'au temps $n$ de la chaîne de Markov de matrice de transtion $R$ et d'état initial $x$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b21768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce97afd7",
   "metadata": {},
   "source": [
    "2) Illustrer graphiquement le comportement en temps long de la chaîne de matrice $P$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09071263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99afe47",
   "metadata": {},
   "source": [
    "3) Donner une estimation des limites des taux d'occupation des états $0$, $1$ et $2$ en comparant selon l'état initial $x$ choisi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe4f537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution\n",
    "# x=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57b285f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x=0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71394fdb",
   "metadata": {},
   "source": [
    "4) Cherchons alors la probabilité invariante de la matrice $P$. La relation $\\pi=\\pi P$ nous dit que $\\pi$ est un vecteur propre à gauche de $P$, et donc en prenant la transposée que $\\pi^t$ est un vecteur propre à droite de $P^t$ (associé à quelle valeur propre ?). On utilisera la commande `np.linalg.eig` qui à une matice $A$ renvoie ses valeurs propres et vecteurs propres et la commande `np.transpose` qui retourne la transposée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42af5880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5fb561",
   "metadata": {},
   "source": [
    "5) Vérifier votre résultat en calculant $\\pi P$. \n",
    "Pensez à normaliser le vecteur $\\pi$ pour qu'il soit bien une probabilité !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d30dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérifions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec762db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérifions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb93b23",
   "metadata": {},
   "source": [
    "6) Comparer le résultat obtenu avec les limites des taux d'occupation des états $0,1,2$ de la question 3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daec1f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution :\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b82070",
   "metadata": {},
   "source": [
    "On vient d'illustrer le théorème ergodique suivant : Si $(X_n)_{n\\geq0}$ est une chaîne de Markov irréductible (c'est-à-dire que tous les états communiquent) sur un espace d'états fini, alors elle admet une unique probabilité invariante $\\pi$, et de plus, pour tout état initial $x\\in E$, on a\n",
    "$$\n",
    "\\lim_{n\\to\\infty} \\frac{1}{n} \\sum_{k=0}^{n-1} P^k(x,y) = \\pi(y).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19193c6",
   "metadata": {},
   "source": [
    "On peut même supposer que $X_0$ suit une loi quelconque $\\mu$, et dans ce cas, on a\n",
    "$$\n",
    "\\lim_{n\\to\\infty} \\frac{1}{n} \\sum_{k=0}^{n-1} \\mu P^k(y) = \\pi(y),\n",
    "$$\n",
    "pour tout $y\\in E$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0748a81",
   "metadata": {},
   "source": [
    "Le théorème est faux si la chaîne n'est pas irréductible comme on pourra s'en convaincre en étudiant la chaîne à deux états de matrice de transition l'identité."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352dd5a4",
   "metadata": {},
   "source": [
    "7) Générer une trajectoire de la chaîne de Markov de matrice $P$ et de loi initiale une loi quelconque $\\mu$ sur $\\{0,1,2\\}$, et comparer les taux d'occupation dans le cas $\\mu=(\\frac17 \\frac27 \\frac47)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aae3268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70dcf854",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c6c4e5",
   "metadata": {},
   "source": [
    "8) Coder les indicateurs $N_{0,0}^{1000} = \\sum_{i=0}^{999}\\mathbf{1}_{x_i=0,x_{i+1}=0}$, $N_{0,1}^{1000}$, et $N_{0,2}^{1000}$ de l'exercice 6.5 du TD sur une trajectoire de 1000 pas commençant en 0. Quelles estimations sur $P$ pourrait-on faire si on avait uniquement ces indicateurs ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9be8384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a697c87c",
   "metadata": {},
   "source": [
    "## 3 - La marche aléatoire sur $\\mathbb Z$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a64732d",
   "metadata": {},
   "source": [
    "On va regarder un exemple de chaîne de Markov sur un espace dénombrable : la marche aléatoire sur $\\mathbb Z$. A chaque instant de temps, le marcheur fait un pas en avant avec probabilité $1/2$ ou un pas en arrière avec probabilité $1/2$. On suppose que le marcheur est initialement en 0. On modélise la position du marcheur au temps $n$ par la suite de v.a. $(X_n)_{n\\geq0}$ définie par $X_0=0$, et\n",
    "$$\n",
    "X_n=Y_1+\\cdots+Y_n,\n",
    "$$\n",
    "où $(Y_i)_{i\\geq1}$ est une suite de v.a. indépendantes et identiquement distribuées, de loi $\\frac12\\delta_{+1}+\\frac12\\delta_{-1}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e8e1f4",
   "metadata": {},
   "source": [
    "1) Ecrire une fonction qui retourne la position (aléatoire) du marcheur au temps $n$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3970fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d56e16",
   "metadata": {},
   "source": [
    "2) Tracer une trajectoire du marcheur jusqu'au temps 1000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68657cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1618a00",
   "metadata": {},
   "source": [
    "3) Tracer plusieurs trajectoires du marcheur sur le même graphique. Peut-on conjecturer une limite de $X_n$ quand $n\\to \\infty$ ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5b33d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeba5ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb448640",
   "metadata": {},
   "source": [
    "$\\mathcal{FIN}$."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
